{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting jsonlines\n",
      "  Using cached jsonlines-3.1.0-py3-none-any.whl (8.6 kB)\n",
      "Collecting attrs>=19.2.0\n",
      "  Using cached attrs-23.1.0-py3-none-any.whl (61 kB)\n",
      "Installing collected packages: attrs, jsonlines\n",
      "Successfully installed attrs-23.1.0 jsonlines-3.1.0\n",
      "Collecting sparqlwrapper\n",
      "  Using cached SPARQLWrapper-2.0.0-py3-none-any.whl (28 kB)\n",
      "Collecting rdflib>=6.1.1\n",
      "  Downloading rdflib-7.0.0-py3-none-any.whl (531 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m531.9/531.9 kB\u001b[0m \u001b[31m5.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting pyparsing<4,>=2.1.0\n",
      "  Downloading pyparsing-3.1.1-py3-none-any.whl (103 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m103.1/103.1 kB\u001b[0m \u001b[31m3.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting isodate<0.7.0,>=0.6.0\n",
      "  Using cached isodate-0.6.1-py2.py3-none-any.whl (41 kB)\n",
      "Requirement already satisfied: six in /opt/homebrew/Caskroom/miniforge/base/envs/knowledge-enhanced-lm-training/lib/python3.9/site-packages (from isodate<0.7.0,>=0.6.0->rdflib>=6.1.1->sparqlwrapper) (1.16.0)\n",
      "Installing collected packages: pyparsing, isodate, rdflib, sparqlwrapper\n",
      "Successfully installed isodate-0.6.1 pyparsing-3.1.1 rdflib-7.0.0 sparqlwrapper-2.0.0\n",
      "Collecting tqdm\n",
      "  Downloading tqdm-4.66.1-py3-none-any.whl (78 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m78.3/78.3 kB\u001b[0m \u001b[31m1.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: tqdm\n",
      "Successfully installed tqdm-4.66.1\n"
     ]
    }
   ],
   "source": [
    "!pip install jsonlines\n",
    "!pip install sparqlwrapper\n",
    "!pip install tqdm\n",
    "\n",
    "import os\n",
    "import json\n",
    "\n",
    "from SPARQLWrapper import SPARQLWrapper, JSON\n",
    "import jsonlines"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get dict of all predicate labels "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "trex_dir = \"../TREx\"\n",
    "pid_list = []\n",
    "\n",
    "for f in os.listdir(trex_dir):\n",
    "    with open(os.path.join(trex_dir, f)) as json_file:\n",
    "        f_content = list(json_file)\n",
    "    pid = json.loads(f_content[0])[\"predicate_id\"]\n",
    "    pid_list += [pid]\n",
    "\n",
    "assert len(pid_list) == 41"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_agent = 'AGENT NAME' ## Customize\n",
    "sparql = SPARQLWrapper(\"https://query.wikidata.org/sparql\", agent=user_agent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "pid_name_labels = {}\n",
    "for pid in pid_list:\n",
    "    search_item = f\"{{(wdt:{pid})}}\"\n",
    "    service = \"\"\"{ bd:serviceParam wikibase:language \"en\". }\"\"\"\n",
    "    sparql.setQuery(f\"\"\" \n",
    "                    SELECT ?wdLabel WHERE \n",
    "    {{\n",
    "                    VALUES (?wdt) {search_item}\n",
    "                    ?wd wikibase:directClaim ?wdt .\n",
    "                    SERVICE wikibase:label {service}\n",
    "    }}\n",
    "    \"\"\")\n",
    "    sparql.setReturnFormat(JSON)\n",
    "    query_result = sparql.query().convert()\n",
    "    try:\n",
    "        pid_name_labels[pid] = query_result[\"results\"][\"bindings\"][0][\"wdLabel\"][\"value\"]\n",
    "    except:\n",
    "        pass\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'P740': 'location of formation',\n",
       " 'P108': 'employer',\n",
       " 'P190': 'twinned administrative body',\n",
       " 'P27': 'country of citizenship',\n",
       " 'P1376': 'capital of',\n",
       " 'P131': 'located in the administrative territorial entity',\n",
       " 'P937': 'work location',\n",
       " 'P176': 'manufacturer',\n",
       " 'P463': 'member of',\n",
       " 'P20': 'place of death',\n",
       " 'P136': 'genre',\n",
       " 'P39': 'position held',\n",
       " 'P407': 'language of work or name',\n",
       " 'P527': 'has part(s)',\n",
       " 'P276': 'location',\n",
       " 'P19': 'place of birth',\n",
       " 'P47': 'shares border with',\n",
       " 'P101': 'field of work',\n",
       " 'P1303': 'instrument',\n",
       " 'P17': 'country',\n",
       " 'P127': 'owned by',\n",
       " 'P103': 'native language',\n",
       " 'P31': 'instance of',\n",
       " 'P159': 'headquarters location',\n",
       " 'P530': 'diplomatic relation',\n",
       " 'P495': 'country of origin',\n",
       " 'P37': 'official language',\n",
       " 'P138': 'named after',\n",
       " 'P361': 'part of',\n",
       " 'P140': 'religion or worldview',\n",
       " 'P1001': 'applies to jurisdiction',\n",
       " 'P30': 'continent',\n",
       " 'P178': 'developer',\n",
       " 'P279': 'subclass of',\n",
       " 'P449': 'original broadcaster',\n",
       " 'P364': 'original language of film or TV show',\n",
       " 'P1412': 'languages spoken, written or signed',\n",
       " 'P264': 'record label',\n",
       " 'P36': 'capital',\n",
       " 'P106': 'occupation',\n",
       " 'P413': 'position played on team / speciality'}"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pid_name_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"predicate_labels.json\", \"w\") as f:\n",
    "    json.dump(pid_name_labels, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analyze distributions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pandas\n",
      "  Downloading pandas-2.0.3-cp39-cp39-macosx_11_0_arm64.whl (10.9 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10.9/10.9 MB\u001b[0m \u001b[31m12.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting pytz>=2020.1\n",
      "  Using cached pytz-2023.3-py2.py3-none-any.whl (502 kB)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /opt/homebrew/Caskroom/miniforge/base/envs/knowledge-enhanced-lm-training/lib/python3.9/site-packages (from pandas) (2.8.2)\n",
      "Requirement already satisfied: numpy>=1.20.3 in /opt/homebrew/Caskroom/miniforge/base/envs/knowledge-enhanced-lm-training/lib/python3.9/site-packages (from pandas) (1.25.2)\n",
      "Collecting tzdata>=2022.1\n",
      "  Using cached tzdata-2023.3-py2.py3-none-any.whl (341 kB)\n",
      "Requirement already satisfied: six>=1.5 in /opt/homebrew/Caskroom/miniforge/base/envs/knowledge-enhanced-lm-training/lib/python3.9/site-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n",
      "Installing collected packages: pytz, tzdata, pandas\n",
      "Successfully installed pandas-2.0.3 pytz-2023.3 tzdata-2023.3\n"
     ]
    }
   ],
   "source": [
    "!pip install pandas\n",
    "\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create tables for locations and languages including essential information for later analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "location_predicates_obj = [\"P36\", \"P740\", \"P190\", \"P27\", \"P47\", \"P1376\", \"P937\", \"P131\", \"P20\", \"P276\", \"P19\", \"P17\", \"P159\", \"P495\", \"P1001\", \"P30\"]\n",
    "location_predicates_sub = [\"P36\", \"P190\", \"P1376\", \"P131\", \"P47\", \"P37\", \"P30\"]\n",
    "person_predicates_sub = [\"P108\", \"P27\", \"P937\", \"P20\", \"P19\", \"P101\", \"P103\", \"P1412\", \"P106\", \"P413\"] \n",
    "language_predicates_obj = [\"P407\", \"P103\", \"P37\", \"P364\", \"P1412\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"predicate_labels.json\", \"r\") as json_file:\n",
    "    pid_name_labels = json.load(json_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trex_dir = \"../TREx\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "trex_locations = []\n",
    "\n",
    "for p in set(location_predicates_obj + location_predicates_sub):\n",
    "    with open(os.path.join(trex_dir, f\"{p}.jsonl\")) as json_file:\n",
    "        f_content = list(json_file)\n",
    "    for l in f_content:\n",
    "        list_item = json.loads(l)\n",
    "        pid = list_item[\"predicate_id\"]\n",
    "        trex_locations += [{\n",
    "            \"predicate_id\" : pid, \n",
    "            \"predicate_label\": pid_name_labels[pid],\n",
    "            \"obj_label\" : list_item[\"obj_label\"],\n",
    "            \"sub_label\" : list_item[\"sub_label\"],\n",
    "            \"location_is_obj\" : p in location_predicates_obj,\n",
    "            \"location_is_sub\" : p in location_predicates_sub,\n",
    "            \"obj_uri\" : list_item[\"sub_uri\"],\n",
    "            \"sub_uri\" : list_item[\"sub_uri\"],\n",
    "            }]\n",
    "\n",
    "trex_locations_df = pd.DataFrame(trex_locations)\n",
    "trex_locations_df.to_csv(\"trex_locations.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "trex_languages = []\n",
    "\n",
    "for p in set(language_predicates_obj):\n",
    "    with open(os.path.join(trex_dir, f\"{p}.jsonl\")) as json_file:\n",
    "        f_content = list(json_file)\n",
    "    for l in f_content:\n",
    "        list_item = json.loads(l)\n",
    "        pid = list_item[\"predicate_id\"]\n",
    "        trex_languages += [{\n",
    "            \"predicate_id\" : pid, \n",
    "            \"predicate_label\": pid_name_labels[pid],\n",
    "            \"obj_label\" : list_item[\"obj_label\"],\n",
    "            \"sub_label\" : list_item[\"sub_label\"],\n",
    "            \"sub_uri\" : list_item[\"sub_uri\"]\n",
    "            # all language-related items are subjects in the templates\n",
    "            }]\n",
    "\n",
    "trex_locations_df = pd.DataFrame(trex_languages)\n",
    "trex_locations_df.to_csv(\"trex_languages.csv\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get person entities and add gender information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load gender map: Maps Wikidata gender ids to labels (str)\n",
    "path_to_gender_map = \"YOUR PATH\" ## Customize\n",
    "with open(path_to_gender_map, \"r\") as f:\n",
    "    gender_map = json.load(f)[\"map\"] \n",
    "\n",
    "# Get local file with list of Wikidata entities including gender info\n",
    "path_to_wiki_entities = \"YOUR PATH\" ## Customize\n",
    "with open(path_to_wiki_entities) as json_file:\n",
    "    wikidata_entity_list = list(json_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make entity list simpler for better querying of gender: maps person id to gender id\n",
    "simple_entity_list = {}\n",
    "for entity in wikidata_entity_list:\n",
    "    entity = json.loads(entity)\n",
    "    simple_entity_list[entity[\"entity_id\"]] = entity[\"gender\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_agent = 'AGENT NAME' ## Customize\n",
    "sparql = SPARQLWrapper(\"https://query.wikidata.org/sparql\", agent=user_agent)\n",
    "\n",
    "def get_entity_gender_from_wikidata(entity_uri):\n",
    "    # Query gender through SPARQL if person id is not in the local dump\n",
    "    sparql.setQuery(f\"\"\" \n",
    "    SELECT * WHERE {{\n",
    "    wd:{entity_uri} wdt:P21 ?gender .\n",
    "    SERVICE wikibase:label {{ bd:serviceParam wikibase:language \"[AUTO_LANGUAGE],en\". }}\n",
    "    }}\n",
    "    \"\"\")\n",
    "    sparql.setReturnFormat(JSON)\n",
    "    query_result = sparql.query().convert()\n",
    "    try:\n",
    "        return query_result[\"results\"][\"bindings\"][0][\"gender\"][\"value\"].split(\"/\")[-1]\n",
    "    except:\n",
    "        return \"NA\"\n",
    "\n",
    "def get_gender_of_entity(entity_uri):\n",
    "    # Get gender information for a specific person entity\n",
    "    gender_id = simple_entity_list.get(entity_uri, \"NA\")\n",
    "    if gender_id == \"NA\":\n",
    "        gender_id = get_entity_gender_from_wikidata(entity_uri)\n",
    "        if gender_id == \"NA\":\n",
    "            print(\"No gender info available for\", entity_uri)\n",
    "    gender_string = gender_map.get(gender_id, \"NA\")\n",
    "    return gender_string\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No gender info available for Q5605925\n",
      "No gender info available for Q5639595\n",
      "No gender info available for Q378422\n",
      "No gender info available for Q7916974\n",
      "No gender info available for Q179132\n",
      "No gender info available for Q1454986\n",
      "No gender info available for Q4612907\n",
      "No gender info available for Q47913\n",
      "No gender info available for Q580606\n",
      "No gender info available for Q44703\n",
      "No gender info available for Q1379239\n",
      "No gender info available for Q179677\n",
      "No gender info available for Q46857\n",
      "No gender info available for Q2125835\n",
      "No gender info available for Q920064\n",
      "No gender info available for Q221395\n",
      "No gender info available for Q980357\n",
      "No gender info available for Q357503\n",
      "No gender info available for Q383092\n",
      "No gender info available for Q674113\n",
      "No gender info available for Q189210\n",
      "No gender info available for Q946028\n",
      "No gender info available for Q669166\n",
      "No gender info available for Q2470594\n",
      "No gender info available for Q3567687\n",
      "No gender info available for Q1815078\n",
      "No gender info available for Q2085148\n",
      "No gender info available for Q217327\n",
      "No gender info available for Q7113626\n",
      "No gender info available for Q1530721\n",
      "No gender info available for Q1210792\n",
      "No gender info available for Q7191247\n",
      "No gender info available for Q675351\n",
      "No gender info available for Q1886249\n",
      "No gender info available for Q38774\n",
      "No gender info available for Q891109\n",
      "No gender info available for Q5593802\n",
      "No gender info available for Q10729872\n",
      "No gender info available for Q1653280\n",
      "No gender info available for Q150681\n",
      "No gender info available for Q213563\n",
      "No gender info available for Q542084\n",
      "No gender info available for Q1888743\n",
      "No gender info available for Q1214385\n",
      "No gender info available for Q901579\n",
      "No gender info available for Q1502348\n",
      "No gender info available for Q5535518\n",
      "No gender info available for Q7757011\n",
      "No gender info available for Q443153\n",
      "No gender info available for Q192864\n",
      "No gender info available for Q488415\n",
      "No gender info available for Q2331\n",
      "No gender info available for Q5318596\n",
      "No gender info available for Q3507471\n",
      "No gender info available for Q1376897\n",
      "No gender info available for Q11509930\n",
      "No gender info available for Q7181635\n",
      "No gender info available for Q167558\n",
      "No gender info available for Q2069518\n",
      "No gender info available for Q781585\n",
      "No gender info available for Q2843522\n",
      "No gender info available for Q1716735\n",
      "No gender info available for Q17182282\n",
      "No gender info available for Q247474\n",
      "No gender info available for Q2910873\n",
      "No gender info available for Q213563\n",
      "No gender info available for Q1284744\n",
      "No gender info available for Q3522472\n",
      "No gender info available for Q1427258\n",
      "No gender info available for Q3944822\n",
      "No gender info available for Q3963314\n",
      "No gender info available for Q2000812\n",
      "No gender info available for Q2563786\n",
      "No gender info available for Q3284399\n",
      "No gender info available for Q3997173\n",
      "No gender info available for Q1235943\n",
      "No gender info available for Q627517\n",
      "No gender info available for Q17080465\n",
      "No gender info available for Q122960\n",
      "No gender info available for Q4154059\n",
      "No gender info available for Q8068538\n",
      "No gender info available for Q2366673\n",
      "No gender info available for Q7427317\n",
      "No gender info available for Q599145\n",
      "No gender info available for Q671780\n",
      "No gender info available for Q2590074\n",
      "No gender info available for Q5247396\n",
      "No gender info available for Q6203279\n",
      "No gender info available for Q367143\n",
      "No gender info available for Q49542\n",
      "No gender info available for Q622283\n",
      "No gender info available for Q1998273\n",
      "No gender info available for Q18913178\n",
      "No gender info available for Q1192364\n",
      "No gender info available for Q165192\n",
      "No gender info available for Q1673765\n",
      "No gender info available for Q311762\n",
      "No gender info available for Q1057292\n",
      "No gender info available for Q1673765\n",
      "No gender info available for Q18206631\n",
      "No gender info available for Q5548845\n",
      "No gender info available for Q980\n",
      "No gender info available for Q6265369\n",
      "No gender info available for Q154797\n",
      "No gender info available for Q182436\n",
      "No gender info available for Q18233\n",
      "No gender info available for Q1683281\n"
     ]
    }
   ],
   "source": [
    "# Make list of dicts with person entity infos\n",
    "trex_people = []\n",
    "\n",
    "for p in set(person_predicates_sub):\n",
    "    with open(os.path.join(trex_dir, f\"{p}.jsonl\")) as json_file:\n",
    "        f_content = list(json_file)\n",
    "    for l in f_content:\n",
    "        list_item = json.loads(l)\n",
    "        pid = list_item[\"predicate_id\"]\n",
    "        uri = list_item[\"sub_uri\"]\n",
    "        trex_people += [{\n",
    "            \"predicate_id\" : pid, \n",
    "            \"predicate_label\": pid_name_labels[pid],\n",
    "            \"obj_label\" : list_item[\"obj_label\"],\n",
    "            \"sub_label\" : list_item[\"sub_label\"],\n",
    "            \"sub_uri\" : uri,\n",
    "            # all person-related items are subjects in the templates\n",
    "            \"gender\" : get_gender_of_entity(uri)\n",
    "            }]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make table and store\n",
    "trex_locations_df = pd.DataFrame(trex_people)\n",
    "trex_locations_df.to_csv(\"trex_persons.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "gender\n",
       "male               7494\n",
       "female             1146\n",
       "NA                  107\n",
       "non-binary            2\n",
       "trans woman           2\n",
       "female organism       1\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trex_locations_df[\"gender\"].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analyze geospatial distribution (WIP)\n",
    "\n",
    "Tutorial: https://towardsdatascience.com/using-python-to-create-a-world-map-from-a-list-of-country-names-cd7480d03b10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pycountry-convert in /opt/homebrew/Caskroom/miniforge/base/envs/knowledge-enhanced-lm-training/lib/python3.9/site-packages (0.7.2)\n",
      "Requirement already satisfied: pytest>=3.4.0 in /opt/homebrew/Caskroom/miniforge/base/envs/knowledge-enhanced-lm-training/lib/python3.9/site-packages (from pycountry-convert) (7.4.0)\n",
      "Requirement already satisfied: pprintpp>=0.3.0 in /opt/homebrew/Caskroom/miniforge/base/envs/knowledge-enhanced-lm-training/lib/python3.9/site-packages (from pycountry-convert) (0.4.0)\n",
      "Requirement already satisfied: pytest-mock>=1.6.3 in /opt/homebrew/Caskroom/miniforge/base/envs/knowledge-enhanced-lm-training/lib/python3.9/site-packages (from pycountry-convert) (3.11.1)\n",
      "Requirement already satisfied: pycountry>=16.11.27.1 in /opt/homebrew/Caskroom/miniforge/base/envs/knowledge-enhanced-lm-training/lib/python3.9/site-packages (from pycountry-convert) (22.3.5)\n",
      "Requirement already satisfied: wheel>=0.30.0 in /opt/homebrew/Caskroom/miniforge/base/envs/knowledge-enhanced-lm-training/lib/python3.9/site-packages (from pycountry-convert) (0.38.4)\n",
      "Requirement already satisfied: repoze.lru>=0.7 in /opt/homebrew/Caskroom/miniforge/base/envs/knowledge-enhanced-lm-training/lib/python3.9/site-packages (from pycountry-convert) (0.7)\n",
      "Requirement already satisfied: pytest-cov>=2.5.1 in /opt/homebrew/Caskroom/miniforge/base/envs/knowledge-enhanced-lm-training/lib/python3.9/site-packages (from pycountry-convert) (4.1.0)\n",
      "Requirement already satisfied: setuptools in /opt/homebrew/Caskroom/miniforge/base/envs/knowledge-enhanced-lm-training/lib/python3.9/site-packages (from pycountry>=16.11.27.1->pycountry-convert) (66.0.0)\n",
      "Requirement already satisfied: iniconfig in /opt/homebrew/Caskroom/miniforge/base/envs/knowledge-enhanced-lm-training/lib/python3.9/site-packages (from pytest>=3.4.0->pycountry-convert) (2.0.0)\n",
      "Requirement already satisfied: tomli>=1.0.0 in /opt/homebrew/Caskroom/miniforge/base/envs/knowledge-enhanced-lm-training/lib/python3.9/site-packages (from pytest>=3.4.0->pycountry-convert) (2.0.1)\n",
      "Requirement already satisfied: exceptiongroup>=1.0.0rc8 in /opt/homebrew/Caskroom/miniforge/base/envs/knowledge-enhanced-lm-training/lib/python3.9/site-packages (from pytest>=3.4.0->pycountry-convert) (1.1.3)\n",
      "Requirement already satisfied: packaging in /opt/homebrew/Caskroom/miniforge/base/envs/knowledge-enhanced-lm-training/lib/python3.9/site-packages (from pytest>=3.4.0->pycountry-convert) (23.1)\n",
      "Requirement already satisfied: pluggy<2.0,>=0.12 in /opt/homebrew/Caskroom/miniforge/base/envs/knowledge-enhanced-lm-training/lib/python3.9/site-packages (from pytest>=3.4.0->pycountry-convert) (1.3.0)\n",
      "Requirement already satisfied: coverage[toml]>=5.2.1 in /opt/homebrew/Caskroom/miniforge/base/envs/knowledge-enhanced-lm-training/lib/python3.9/site-packages (from pytest-cov>=2.5.1->pycountry-convert) (7.3.0)\n",
      "Requirement already satisfied: geopy in /opt/homebrew/Caskroom/miniforge/base/envs/knowledge-enhanced-lm-training/lib/python3.9/site-packages (2.4.0)\n",
      "Requirement already satisfied: geographiclib<3,>=1.52 in /opt/homebrew/Caskroom/miniforge/base/envs/knowledge-enhanced-lm-training/lib/python3.9/site-packages (from geopy) (2.0)\n",
      "Collecting numpy\n",
      "  Downloading numpy-1.25.2-cp39-cp39-macosx_11_0_arm64.whl (14.0 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m14.0/14.0 MB\u001b[0m \u001b[31m11.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: numpy\n",
      "Successfully installed numpy-1.25.2\n"
     ]
    }
   ],
   "source": [
    "!pip install pycountry-convert\n",
    "!pip install geopy\n",
    "!pip install numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pycountry_convert import country_alpha2_to_continent_code, country_name_to_country_alpha2\n",
    "from geopy.geocoders import Nominatim\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_continent(col):\n",
    "    try:\n",
    "        cn_a2_code =  country_name_to_country_alpha2(col)\n",
    "    except:\n",
    "        cn_a2_code = 'Unknown' \n",
    "    try:\n",
    "        cn_continent = country_alpha2_to_continent_code(cn_a2_code)\n",
    "    except:\n",
    "        cn_continent = 'Unknown' \n",
    "    return (cn_a2_code, cn_continent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "geolocator = Nominatim(user_agent=\"trex_eda\")\n",
    "def geolocate(country):\n",
    "    try:\n",
    "        # Geolocate the center of the country\n",
    "        loc = geolocator.geocode(country)\n",
    "        # And return latitude and longitude\n",
    "        return (loc.latitude, loc.longitude)\n",
    "    except:\n",
    "        # Return missing value\n",
    "        return np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "knowledge-enhanced-lm-training",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
