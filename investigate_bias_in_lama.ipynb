{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: jsonlines in /opt/homebrew/Caskroom/miniforge/base/envs/knowledge-enhanced-lm-training/lib/python3.9/site-packages (3.1.0)\n",
      "Requirement already satisfied: attrs>=19.2.0 in /opt/homebrew/Caskroom/miniforge/base/envs/knowledge-enhanced-lm-training/lib/python3.9/site-packages (from jsonlines) (23.1.0)\n",
      "Requirement already satisfied: sparqlwrapper in /opt/homebrew/Caskroom/miniforge/base/envs/knowledge-enhanced-lm-training/lib/python3.9/site-packages (2.0.0)\n",
      "Requirement already satisfied: rdflib>=6.1.1 in /opt/homebrew/Caskroom/miniforge/base/envs/knowledge-enhanced-lm-training/lib/python3.9/site-packages (from sparqlwrapper) (7.0.0)\n",
      "Requirement already satisfied: isodate<0.7.0,>=0.6.0 in /opt/homebrew/Caskroom/miniforge/base/envs/knowledge-enhanced-lm-training/lib/python3.9/site-packages (from rdflib>=6.1.1->sparqlwrapper) (0.6.1)\n",
      "Requirement already satisfied: pyparsing<4,>=2.1.0 in /opt/homebrew/Caskroom/miniforge/base/envs/knowledge-enhanced-lm-training/lib/python3.9/site-packages (from rdflib>=6.1.1->sparqlwrapper) (3.1.1)\n",
      "Requirement already satisfied: six in /opt/homebrew/Caskroom/miniforge/base/envs/knowledge-enhanced-lm-training/lib/python3.9/site-packages (from isodate<0.7.0,>=0.6.0->rdflib>=6.1.1->sparqlwrapper) (1.16.0)\n",
      "Requirement already satisfied: tqdm in /opt/homebrew/Caskroom/miniforge/base/envs/knowledge-enhanced-lm-training/lib/python3.9/site-packages (4.66.1)\n"
     ]
    }
   ],
   "source": [
    "!pip install jsonlines\n",
    "!pip install sparqlwrapper\n",
    "!pip install tqdm\n",
    "\n",
    "import os\n",
    "import json\n",
    "\n",
    "from SPARQLWrapper import SPARQLWrapper, JSON\n",
    "import jsonlines"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get dict of all predicate labels "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "trex_dir = \"../TREx\"\n",
    "pid_list = []\n",
    "\n",
    "for f in os.listdir(trex_dir):\n",
    "    with open(os.path.join(trex_dir, f)) as json_file:\n",
    "        f_content = list(json_file)\n",
    "    pid = json.loads(f_content[0])[\"predicate_id\"]\n",
    "    pid_list += [pid]\n",
    "\n",
    "assert len(pid_list) == 41"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_agent = 'AGENT NAME' ## Customize\n",
    "sparql = SPARQLWrapper(\"https://query.wikidata.org/sparql\", agent=user_agent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pid_name_labels = {}\n",
    "for pid in pid_list:\n",
    "    search_item = f\"{{(wdt:{pid})}}\"\n",
    "    service = \"\"\"{ bd:serviceParam wikibase:language \"en\". }\"\"\"\n",
    "    sparql.setQuery(f\"\"\" \n",
    "                    SELECT ?wdLabel WHERE \n",
    "    {{\n",
    "                    VALUES (?wdt) {search_item}\n",
    "                    ?wd wikibase:directClaim ?wdt .\n",
    "                    SERVICE wikibase:label {service}\n",
    "    }}\n",
    "    \"\"\")\n",
    "    sparql.setReturnFormat(JSON)\n",
    "    query_result = sparql.query().convert()\n",
    "    try:\n",
    "        pid_name_labels[pid] = query_result[\"results\"][\"bindings\"][0][\"wdLabel\"][\"value\"]\n",
    "    except:\n",
    "        pass\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pid_name_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"predicate_labels.json\", \"w\") as f:\n",
    "    json.dump(pid_name_labels, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analyze distributions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pandas in /opt/homebrew/Caskroom/miniforge/base/envs/knowledge-enhanced-lm-training/lib/python3.9/site-packages (2.0.3)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /opt/homebrew/Caskroom/miniforge/base/envs/knowledge-enhanced-lm-training/lib/python3.9/site-packages (from pandas) (2.8.2)\n",
      "Requirement already satisfied: tzdata>=2022.1 in /opt/homebrew/Caskroom/miniforge/base/envs/knowledge-enhanced-lm-training/lib/python3.9/site-packages (from pandas) (2023.3)\n",
      "Requirement already satisfied: numpy>=1.20.3 in /opt/homebrew/Caskroom/miniforge/base/envs/knowledge-enhanced-lm-training/lib/python3.9/site-packages (from pandas) (1.25.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /opt/homebrew/Caskroom/miniforge/base/envs/knowledge-enhanced-lm-training/lib/python3.9/site-packages (from pandas) (2023.3)\n",
      "Requirement already satisfied: six>=1.5 in /opt/homebrew/Caskroom/miniforge/base/envs/knowledge-enhanced-lm-training/lib/python3.9/site-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install pandas\n",
    "\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create tables for locations and languages including essential information for later analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "location_predicates_obj = [\"P36\", \"P740\", \"P190\", \"P27\", \"P47\", \"P1376\", \"P937\", \"P131\", \"P20\", \"P276\", \"P19\", \"P17\", \"P159\", \"P495\", \"P1001\", \"P30\"]\n",
    "location_predicates_sub = [\"P36\", \"P190\", \"P1376\", \"P131\", \"P47\", \"P37\", \"P30\"]\n",
    "person_predicates_sub = [\"P108\", \"P27\", \"P937\", \"P20\", \"P19\", \"P101\", \"P103\", \"P1412\", \"P106\", \"P413\"] \n",
    "language_predicates_obj = [\"P407\", \"P103\", \"P37\", \"P364\", \"P1412\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"predicate_labels.json\", \"r\") as json_file:\n",
    "    pid_name_labels = json.load(json_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "trex_dir = \"../TREx\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "trex_locations = []\n",
    "\n",
    "for p in set(location_predicates_obj + location_predicates_sub):\n",
    "    with open(os.path.join(trex_dir, f\"{p}.jsonl\")) as json_file:\n",
    "        f_content = list(json_file)\n",
    "    for l in f_content:\n",
    "        list_item = json.loads(l)\n",
    "        pid = list_item[\"predicate_id\"]\n",
    "        trex_locations += [{\n",
    "            \"uuid\" : list_item[\"uuid\"],\n",
    "            \"predicate_id\" : pid, \n",
    "            \"predicate_label\": pid_name_labels[pid],\n",
    "            \"obj_label\" : list_item[\"obj_label\"],\n",
    "            \"sub_label\" : list_item[\"sub_label\"],\n",
    "            \"location_is_obj\" : p in location_predicates_obj,\n",
    "            \"location_is_sub\" : p in location_predicates_sub,\n",
    "            \"obj_uri\" : list_item[\"sub_uri\"],\n",
    "            \"sub_uri\" : list_item[\"sub_uri\"],\n",
    "            }]\n",
    "\n",
    "trex_locations_df = pd.DataFrame(trex_locations)\n",
    "trex_locations_df.to_csv(\"trex_locations_uuid.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "trex_languages = []\n",
    "\n",
    "for p in set(language_predicates_obj):\n",
    "    with open(os.path.join(trex_dir, f\"{p}.jsonl\")) as json_file:\n",
    "        f_content = list(json_file)\n",
    "    for l in f_content:\n",
    "        list_item = json.loads(l)\n",
    "        pid = list_item[\"predicate_id\"]\n",
    "        trex_languages += [{\n",
    "            \"uuid\" : list_item[\"uuid\"],\n",
    "            \"predicate_id\" : pid, \n",
    "            \"predicate_label\": pid_name_labels[pid],\n",
    "            \"obj_label\" : list_item[\"obj_label\"],\n",
    "            \"sub_label\" : list_item[\"sub_label\"],\n",
    "            \"sub_uri\" : list_item[\"sub_uri\"]\n",
    "            # all language-related items are subjects in the templates\n",
    "            }]\n",
    "\n",
    "trex_locations_df = pd.DataFrame(trex_languages)\n",
    "trex_locations_df.to_csv(\"trex_languages.csv\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get person entities and add gender information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load gender map: Maps Wikidata gender ids to labels (str)\n",
    "path_to_gender_map = \"PATH-TO/wikidata_genders.json\" ## Customize\n",
    "with open(path_to_gender_map, \"r\") as f:\n",
    "    gender_map = json.load(f)[\"map\"] \n",
    "\n",
    "# Get local file with list of Wikidata entities including gender info\n",
    "path_to_wiki_entities = \"PATH-TO/wikidata_all_human_entities.jsonl\" ## Customize\n",
    "with open(path_to_wiki_entities) as json_file:\n",
    "    wikidata_entity_list = list(json_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make entity list simpler for better querying of gender: maps person id to gender id\n",
    "simple_entity_list = {}\n",
    "for entity in wikidata_entity_list:\n",
    "    entity = json.loads(entity)\n",
    "    simple_entity_list[entity[\"entity_id\"]] = entity[\"gender\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_agent = 'AGENT NAME' ## Customize\n",
    "sparql = SPARQLWrapper(\"https://query.wikidata.org/sparql\", agent=user_agent)\n",
    "\n",
    "def get_entity_gender_from_wikidata(entity_uri):\n",
    "    # Query gender through SPARQL if person id is not in the local dump\n",
    "    sparql.setQuery(f\"\"\" \n",
    "    SELECT * WHERE {{\n",
    "    wd:{entity_uri} wdt:P21 ?gender .\n",
    "    SERVICE wikibase:label {{ bd:serviceParam wikibase:language \"[AUTO_LANGUAGE],en\". }}\n",
    "    }}\n",
    "    \"\"\")\n",
    "    sparql.setReturnFormat(JSON)\n",
    "    query_result = sparql.query().convert()\n",
    "    try:\n",
    "        return query_result[\"results\"][\"bindings\"][0][\"gender\"][\"value\"].split(\"/\")[-1]\n",
    "    except:\n",
    "        return \"NaN\"\n",
    "\n",
    "def get_gender_of_entity(entity_uri):\n",
    "    # Get gender information for a specific person entity\n",
    "    gender_id = simple_entity_list.get(entity_uri, \"NaN\")\n",
    "    if gender_id == \"NaN\":\n",
    "        gender_id = get_entity_gender_from_wikidata(entity_uri)\n",
    "        if gender_id == \"NaN\":\n",
    "            print(\"No gender info available for\", entity_uri)\n",
    "    gender_string = gender_map.get(gender_id, \"NaN\")\n",
    "    return gender_string\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No gender info available for Q7427317\n",
      "No gender info available for Q49542\n",
      "No gender info available for Q622283\n",
      "No gender info available for Q1998273\n",
      "No gender info available for Q18913178\n",
      "No gender info available for Q1192364\n",
      "No gender info available for Q165192\n",
      "No gender info available for Q1673765\n",
      "No gender info available for Q311762\n",
      "No gender info available for Q1057292\n",
      "No gender info available for Q1673765\n",
      "No gender info available for Q5639595\n",
      "No gender info available for Q378422\n",
      "No gender info available for Q7916974\n",
      "No gender info available for Q5605925\n",
      "No gender info available for Q179132\n",
      "No gender info available for Q1454986\n",
      "No gender info available for Q4612907\n",
      "No gender info available for Q47913\n",
      "No gender info available for Q580606\n",
      "No gender info available for Q44703\n",
      "No gender info available for Q1379239\n",
      "No gender info available for Q179677\n",
      "No gender info available for Q46857\n",
      "No gender info available for Q2125835\n",
      "No gender info available for Q920064\n",
      "No gender info available for Q221395\n",
      "No gender info available for Q980357\n",
      "No gender info available for Q357503\n",
      "No gender info available for Q383092\n",
      "No gender info available for Q674113\n",
      "No gender info available for Q189210\n",
      "No gender info available for Q946028\n",
      "No gender info available for Q669166\n",
      "No gender info available for Q2470594\n",
      "No gender info available for Q3567687\n",
      "No gender info available for Q1815078\n",
      "No gender info available for Q2085148\n",
      "No gender info available for Q217327\n",
      "No gender info available for Q7113626\n",
      "No gender info available for Q1530721\n",
      "No gender info available for Q1210792\n",
      "No gender info available for Q7191247\n",
      "No gender info available for Q675351\n",
      "No gender info available for Q1886249\n",
      "No gender info available for Q38774\n",
      "No gender info available for Q891109\n",
      "No gender info available for Q5593802\n",
      "No gender info available for Q10729872\n",
      "No gender info available for Q1653280\n",
      "No gender info available for Q150681\n",
      "No gender info available for Q213563\n",
      "No gender info available for Q542084\n",
      "No gender info available for Q1888743\n",
      "No gender info available for Q1214385\n",
      "No gender info available for Q901579\n",
      "No gender info available for Q1502348\n",
      "No gender info available for Q5535518\n",
      "No gender info available for Q7757011\n",
      "No gender info available for Q443153\n",
      "No gender info available for Q192864\n",
      "No gender info available for Q488415\n",
      "No gender info available for Q2331\n",
      "No gender info available for Q5318596\n",
      "No gender info available for Q3507471\n",
      "No gender info available for Q1376897\n",
      "No gender info available for Q11509930\n",
      "No gender info available for Q7181635\n",
      "No gender info available for Q167558\n",
      "No gender info available for Q2069518\n",
      "No gender info available for Q781585\n",
      "No gender info available for Q2843522\n",
      "No gender info available for Q1716735\n",
      "No gender info available for Q17182282\n",
      "No gender info available for Q247474\n",
      "No gender info available for Q2910873\n",
      "No gender info available for Q213563\n",
      "No gender info available for Q1284744\n",
      "No gender info available for Q3522472\n",
      "No gender info available for Q1427258\n",
      "No gender info available for Q3944822\n",
      "No gender info available for Q3963314\n",
      "No gender info available for Q2000812\n",
      "No gender info available for Q2563786\n",
      "No gender info available for Q3284399\n",
      "No gender info available for Q3997173\n",
      "No gender info available for Q1235943\n",
      "No gender info available for Q627517\n",
      "No gender info available for Q17080465\n",
      "No gender info available for Q122960\n",
      "No gender info available for Q4154059\n",
      "No gender info available for Q8068538\n",
      "No gender info available for Q2366673\n",
      "No gender info available for Q18206631\n",
      "No gender info available for Q5548845\n",
      "No gender info available for Q980\n",
      "No gender info available for Q6265369\n",
      "No gender info available for Q154797\n",
      "No gender info available for Q182436\n",
      "No gender info available for Q18233\n",
      "No gender info available for Q1683281\n",
      "No gender info available for Q599145\n",
      "No gender info available for Q671780\n",
      "No gender info available for Q2590074\n",
      "No gender info available for Q5247396\n",
      "No gender info available for Q6203279\n",
      "No gender info available for Q367143\n"
     ]
    }
   ],
   "source": [
    "# Make list of dicts with person entity infos\n",
    "trex_people = []\n",
    "\n",
    "for p in set(person_predicates_sub):\n",
    "    with open(os.path.join(trex_dir, f\"{p}.jsonl\")) as json_file:\n",
    "        f_content = list(json_file)\n",
    "    for l in f_content:\n",
    "        list_item = json.loads(l)\n",
    "        pid = list_item[\"predicate_id\"]\n",
    "        uri = list_item[\"sub_uri\"]\n",
    "        trex_people += [{\n",
    "            \"uuid\" : list_item[\"uuid\"],\n",
    "            \"predicate_id\" : pid, \n",
    "            \"predicate_label\": pid_name_labels[pid],\n",
    "            \"obj_label\" : list_item[\"obj_label\"],\n",
    "            \"sub_label\" : list_item[\"sub_label\"],\n",
    "            \"sub_uri\" : uri,\n",
    "            # all person-related items are subjects in the templates\n",
    "            \"gender\" : get_gender_of_entity(uri)\n",
    "            }]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make table and store\n",
    "trex_locations_df = pd.DataFrame(trex_people)\n",
    "trex_locations_df.to_csv(\"trex_persons.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "gender\n",
       "male               7494\n",
       "female             1146\n",
       "NaN                 107\n",
       "non-binary            2\n",
       "trans woman           2\n",
       "female organism       1\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trex_locations_df[\"gender\"].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analyze geospatial distribution (WIP)\n",
    "\n",
    "Tutorial: https://towardsdatascience.com/using-python-to-create-a-world-map-from-a-list-of-country-names-cd7480d03b10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pycountry-convert in /opt/homebrew/Caskroom/miniforge/base/envs/knowledge-enhanced-lm-training/lib/python3.9/site-packages (0.7.2)\n",
      "Requirement already satisfied: pytest-mock>=1.6.3 in /opt/homebrew/Caskroom/miniforge/base/envs/knowledge-enhanced-lm-training/lib/python3.9/site-packages (from pycountry-convert) (3.11.1)\n",
      "Requirement already satisfied: pprintpp>=0.3.0 in /opt/homebrew/Caskroom/miniforge/base/envs/knowledge-enhanced-lm-training/lib/python3.9/site-packages (from pycountry-convert) (0.4.0)\n",
      "Requirement already satisfied: repoze.lru>=0.7 in /opt/homebrew/Caskroom/miniforge/base/envs/knowledge-enhanced-lm-training/lib/python3.9/site-packages (from pycountry-convert) (0.7)\n",
      "Requirement already satisfied: pytest>=3.4.0 in /opt/homebrew/Caskroom/miniforge/base/envs/knowledge-enhanced-lm-training/lib/python3.9/site-packages (from pycountry-convert) (7.4.0)\n",
      "Requirement already satisfied: wheel>=0.30.0 in /opt/homebrew/Caskroom/miniforge/base/envs/knowledge-enhanced-lm-training/lib/python3.9/site-packages (from pycountry-convert) (0.38.4)\n",
      "Requirement already satisfied: pytest-cov>=2.5.1 in /opt/homebrew/Caskroom/miniforge/base/envs/knowledge-enhanced-lm-training/lib/python3.9/site-packages (from pycountry-convert) (4.1.0)\n",
      "Requirement already satisfied: pycountry>=16.11.27.1 in /opt/homebrew/Caskroom/miniforge/base/envs/knowledge-enhanced-lm-training/lib/python3.9/site-packages (from pycountry-convert) (22.3.5)\n",
      "Requirement already satisfied: setuptools in /opt/homebrew/Caskroom/miniforge/base/envs/knowledge-enhanced-lm-training/lib/python3.9/site-packages (from pycountry>=16.11.27.1->pycountry-convert) (66.0.0)\n",
      "Requirement already satisfied: pluggy<2.0,>=0.12 in /opt/homebrew/Caskroom/miniforge/base/envs/knowledge-enhanced-lm-training/lib/python3.9/site-packages (from pytest>=3.4.0->pycountry-convert) (1.3.0)\n",
      "Requirement already satisfied: packaging in /opt/homebrew/Caskroom/miniforge/base/envs/knowledge-enhanced-lm-training/lib/python3.9/site-packages (from pytest>=3.4.0->pycountry-convert) (23.1)\n",
      "Requirement already satisfied: exceptiongroup>=1.0.0rc8 in /opt/homebrew/Caskroom/miniforge/base/envs/knowledge-enhanced-lm-training/lib/python3.9/site-packages (from pytest>=3.4.0->pycountry-convert) (1.1.3)\n",
      "Requirement already satisfied: iniconfig in /opt/homebrew/Caskroom/miniforge/base/envs/knowledge-enhanced-lm-training/lib/python3.9/site-packages (from pytest>=3.4.0->pycountry-convert) (2.0.0)\n",
      "Requirement already satisfied: tomli>=1.0.0 in /opt/homebrew/Caskroom/miniforge/base/envs/knowledge-enhanced-lm-training/lib/python3.9/site-packages (from pytest>=3.4.0->pycountry-convert) (2.0.1)\n",
      "Requirement already satisfied: coverage[toml]>=5.2.1 in /opt/homebrew/Caskroom/miniforge/base/envs/knowledge-enhanced-lm-training/lib/python3.9/site-packages (from pytest-cov>=2.5.1->pycountry-convert) (7.3.0)\n",
      "Requirement already satisfied: geopy in /opt/homebrew/Caskroom/miniforge/base/envs/knowledge-enhanced-lm-training/lib/python3.9/site-packages (2.4.0)\n",
      "Requirement already satisfied: geographiclib<3,>=1.52 in /opt/homebrew/Caskroom/miniforge/base/envs/knowledge-enhanced-lm-training/lib/python3.9/site-packages (from geopy) (2.0)\n",
      "Requirement already satisfied: numpy in /opt/homebrew/Caskroom/miniforge/base/envs/knowledge-enhanced-lm-training/lib/python3.9/site-packages (1.25.2)\n"
     ]
    }
   ],
   "source": [
    "!pip install pycountry-convert\n",
    "!pip install geopy\n",
    "!pip install numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pycountry_convert import country_alpha2_to_continent_code, country_name_to_country_alpha2\n",
    "from geopy.geocoders import Nominatim\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "tqdm.pandas()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load previously extracted location info\n",
    "trex_locations_df = pd.read_csv(\"trex_locations.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "geolocator = Nominatim(user_agent=\"trex_eda\")\n",
    "def geolocate(location, timeout):\n",
    "    try:        \n",
    "        # Geolocate the center of the country\n",
    "        if timeout == \"default\":\n",
    "            loc = geolocator.geocode(location)\n",
    "        else:\n",
    "            loc = geolocator.geocode(location, timeout=timeout)\n",
    "        # And return latitude and longitude\n",
    "        return (loc.latitude, loc.longitude)\n",
    "    except:\n",
    "        # Return missing value\n",
    "        return \"NaN\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_geolocation_for_row(row, timeout):\n",
    "    if row[\"location_is_sub\"]:\n",
    "        row[\"geolocation_sub\"] = geolocate(row[\"sub_label\"], timeout)\n",
    "    else:\n",
    "        row[\"geolocation_sub\"] = \"NaN\"\n",
    "    if row[\"location_is_obj\"]:\n",
    "        row[\"geolocation_obj\"] = geolocate(row[\"obj_label\"], timeout)\n",
    "    else:\n",
    "        row[\"geolocation_obj\"] = \"NaN\"\n",
    "    return row\n",
    "\n",
    "def get_geolocations_for_df(df, start_idx=0, end_idx=-1, index_list=None, timeout=\"default\"):\n",
    "    if index_list:\n",
    "        return df.iloc[index_list].apply(get_geolocation_for_row, args=[timeout], axis=1)\n",
    "    else:\n",
    "        return df.iloc[start_idx:end_idx].apply(get_geolocation_for_row, args=[timeout], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "import threading\n",
    "\n",
    "# Optionally speed up things through multi-threading\n",
    "\n",
    "class ThreadWithReturnValue(threading.Thread):\n",
    "\n",
    "    def __init__(self, group=None, target=None, name=None,\n",
    "                    args=(), kwargs={}, Verbose=None):\n",
    "        threading.Thread.__init__(self, group, target, name, args, kwargs)\n",
    "        self._return = None\n",
    "\n",
    "    def run(self):\n",
    "        if self._target is not None:\n",
    "            self._return = self._target(*self._args,\n",
    "                                                **self._kwargs)\n",
    "    def join(self, *args):\n",
    "        threading.Thread.join(self, *args)\n",
    "        return self._return\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "thread1 = ThreadWithReturnValue(target=get_geolocations_for_df, args=(trex_locations_df, 0, 3723))\n",
    "thread2 = ThreadWithReturnValue(target=get_geolocations_for_df, args=(trex_locations_df, 3723, 7446))\n",
    "thread3 = ThreadWithReturnValue(target=get_geolocations_for_df, args=(trex_locations_df, 7446, 11169))\n",
    "thread4 = ThreadWithReturnValue(target=get_geolocations_for_df, args=(trex_locations_df, 11169, -1))\n",
    "thread1.start()\n",
    "thread2.start()\n",
    "thread3.start()\n",
    "thread4.start()\n",
    "trex_locations_df = pd.concat([thread1.join(), thread2.join(), thread3.join(), thread4.join()], axis=0, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "trex_locations_df.to_csv(\"trex_locations.csv\") # This will be overwritten later\n",
    "trex_locations_df.to_csv(\"trex_locations_backup.csv\") # Back-up in case sth. goes wrong :)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Due to the fast default timeout in the geolocate function, a couple thousand unresolved locations remain. Re-running geolocate for all unresolved location and add to df:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get all cases where coordinates should exist but weren't resolved so far\n",
    "unresolved_indices = trex_locations_df.index[(trex_locations_df[\"geolocation_sub\"].apply(isinstance, args=(tuple,)) == False) & (trex_locations_df[\"geolocation_obj\"].apply(isinstance, args=(tuple,)) == False)].tolist()\n",
    "len(unresolved_indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Geolocate with longer timeout (did this in two iterations: 3 and then 10)\n",
    "trex_locations_df.iloc[unresolved_indices] = get_geolocations_for_df(trex_locations_df, index_list=unresolved_indices, timeout=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Overwrite location table\n",
    "trex_locations_df.to_csv(\"trex_locations.csv\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create disaggregated datasets in T-REx format"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "knowledge-enhanced-lm-training",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
